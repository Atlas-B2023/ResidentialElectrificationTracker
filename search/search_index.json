{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#atlas-iqp-b23-residential-heating-code-documentation","title":"Atlas IQP B23 Residential Heating Code Documentation","text":"<p>Public functions are documented on the left, although private functions are also document.</p>"},{"location":"Helper/","title":"Helper","text":""},{"location":"Helper/#src.Helper.ASCIIColors","title":"<code>ASCIIColors</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>ASCII colors for use in printing colored text to the terminal.</p> Source code in <code>src\\Helper.py</code> <pre><code>class ASCIIColors(StrEnum):\n    \"\"\"ASCII colors for use in printing colored text to the terminal.\"\"\"\n\n    GREY = \"\\x1b[38;20m\"\n    YELLOW = \"\\x1b[33;20m\"\n    RED = \"\\x1b[31;20m\"\n    BOLD_RED = \"\\x1b[31;1m\"\n    RESET = \"\\x1b[0m\"\n</code></pre>"},{"location":"Helper/#src.Helper.df_to_file","title":"<code>df_to_file(df)</code>","text":"<p>Write a DataFrame to a unique file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>the DataFrame to write</p> required Source code in <code>src\\Helper.py</code> <pre><code>def df_to_file(df: pl.DataFrame):\n    \"\"\"Write a DataFrame to a unique file.\n\n    Args:\n        df (pl.DataFrame): the DataFrame to write\n    \"\"\"\n    file_path = Path(\"./output\") / \"{time.time()}_data_frame.csv\"\n\n    if \"HEATING AMENITIES\" in df.schema:\n        df.with_columns(\n            pl.col(\"HEATING AMENITIES\").map_elements(lambda x: str(x.to_list()))\n        ).write_csv(file_path, has_header=True)\n        print(f\"Dataframe saved to {file_path.resolve()}\")\n    else:\n        print(f\"Dataframe saved to {file_path.resolve()}\")\n        df.write_csv(file_path, has_header=True)\n</code></pre>"},{"location":"Helper/#src.Helper.get_random_user_agent","title":"<code>get_random_user_agent()</code>","text":"<p>Pick a random user agent string from a list of popular user agents.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>user agent string</p> Source code in <code>src\\Helper.py</code> <pre><code>def get_random_user_agent() -&gt; str:\n    \"\"\"Pick a random user agent string from a list of popular user agents.\n\n    Returns:\n        str: user agent string\n    \"\"\"\n    list = [\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.35\",\n        \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/113.0\",\n        \"Mozilla/5.0 (Android 12; Mobile; rv:109.0) Gecko/113.0 Firefox/113.0\",\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n        \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n    ]\n    return random.choice(list)\n</code></pre>"},{"location":"Helper/#src.Helper.get_redfin_url_path","title":"<code>get_redfin_url_path(location)</code>","text":"<p>Generate the URL path with the proprietary Redfin number for the given city, ZIP code, or address.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_redfin_url_path(\"Washington D.C\")\n\"/city/12839/DC/Washington-DC\"\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>the location</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the path to the location</p> Source code in <code>src\\Helper.py</code> <pre><code>def get_redfin_url_path(location: str) -&gt; str:\n    \"\"\"Generate the URL path with the proprietary Redfin number for the given city, ZIP code, or address.\n\n    Examples:\n        &gt;&gt;&gt; get_redfin_url_path(\"Washington D.C\")\n        \"/city/12839/DC/Washington-DC\"\n\n    Args:\n        location (str): the location\n\n    Returns:\n        str: the path to the location\n    \"\"\"\n    client = Redfin()\n    response = client.search(location)\n    return response[\"payload\"][\"sections\"][0][\"rows\"][0][\"url\"]\n</code></pre>"},{"location":"Helper/#src.Helper.is_valid_zipcode","title":"<code>is_valid_zipcode(zip)</code>","text":"<p>Check if the given ZIP code is valid based on a local file.</p> <p>Parameters:</p> Name Type Description Default <code>zip</code> <code>int</code> <p>the ZIP code to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>if ZIP code is valid</p> Source code in <code>src\\Helper.py</code> <pre><code>def is_valid_zipcode(zip: int) -&gt; bool:\n    \"\"\"Check if the given ZIP code is valid based on a local file.\n\n    Args:\n        zip (int): the ZIP code to check\n\n    Returns:\n        bool: if ZIP code is valid\n    \"\"\"\n    # zip codes are stored as numbers in the csv as of 10/28/23\n    df = pl.read_csv(\"./augmenting_data/uszips.csv\")\n\n    return zip in df[\"ZIP\"]\n</code></pre>"},{"location":"Helper/#src.Helper.metro_name_to_zip_code_list","title":"<code>metro_name_to_zip_code_list(msa_name)</code>","text":"<p>Return the constituent ZIP codes for the given Metropolitan Statistical Area.</p> <p>Parameters:</p> Name Type Description Default <code>msa_name</code> <code>str</code> <p>name of the Metropolitan Statistical Area</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: list of ZIP codes found. Is empty if MSA name is invalid</p> Source code in <code>src\\Helper.py</code> <pre><code>def metro_name_to_zip_code_list(msa_name: str) -&gt; list[int]:\n    \"\"\"Return the constituent ZIP codes for the given Metropolitan Statistical Area.\n\n    Args:\n        msa_name (str): name of the Metropolitan Statistical Area\n\n    Returns:\n        list[int]: list of ZIP codes found. Is empty if MSA name is invalid\n    \"\"\"\n    if msa_name == \"TEST\":\n        # return [55424]  # good and small\n        # return [22067, 55424]  # nulls in sqft\n        return [22067, 55424, 33629]  # nulls in sqft and large\n\n    df = pl.read_csv(\"./augmenting_data/master.csv\")\n\n    # MSAs are what were looking for in this project. Some MSA are repeated. can use unique(), but using a select is faster and better\n    return df.filter(\n        (df[\"METRO_NAME\"] == msa_name) &amp; (df[\"LSAD\"] == \"Metropolitan Statistical Area\")\n    )[\"ZIP\"].to_list()\n</code></pre>"},{"location":"Helper/#src.Helper.req_get_to_file","title":"<code>req_get_to_file(request)</code>","text":"<p>Write the contents of a request response to a unique file.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Response</code> <p>the request</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>the status code of the request</p> Source code in <code>src\\Helper.py</code> <pre><code>def req_get_to_file(request: requests.Response) -&gt; int:\n    \"\"\"Write the contents of a request response to a unique file.\n\n    Args:\n        request (requests.Response): the request\n\n    Returns:\n        int: the status code of the request\n    \"\"\"\n    with open(f\"{time.time()}_request.html\", \"w+\", encoding=\"utf-8\") as f:\n        f.write(request.text)\n    return request.status_code\n</code></pre>"},{"location":"Helper/#src.Helper.req_get_wrapper","title":"<code>req_get_wrapper(url)</code>","text":"<p>Wrapper for requests. Uses a random short sleep and random user agent string.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>url to pass to <code>requests.get()</code></p> required <p>Returns:</p> Type Description <code>Response</code> <p>requests.Response: the response object</p> Source code in <code>src\\Helper.py</code> <pre><code>def req_get_wrapper(url: str) -&gt; requests.Response:\n    \"\"\"Wrapper for requests. Uses a random short sleep and random user agent string.\n\n    Args:\n        url (str): url to pass to `requests.get()`\n\n    Returns:\n        requests.Response: the response object\n    \"\"\"\n    time.sleep(random.uniform(0.6, 1.1))\n    req = requests.get(\n        url,\n        headers={\"User-Agent\": get_random_user_agent()},\n        timeout=17,\n    )\n\n    return req\n</code></pre>"},{"location":"Helper/#src.Helper.state_city_to_zip_df","title":"<code>state_city_to_zip_df(state, city)</code>","text":"<p>Take in a state and city and return the ZIP code constituents of that city.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>the state</p> required <code>city</code> <code>str</code> <p>the city</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: DataFrame of ZIP codes</p> Source code in <code>src\\Helper.py</code> <pre><code>def state_city_to_zip_df(state: str, city: str) -&gt; pl.DataFrame:\n    \"\"\"Take in a state and city and return the ZIP code constituents of that city.\n\n    Args:\n        state (str): the state\n        city (str): the city\n\n    Returns:\n        pl.DataFrame: DataFrame of ZIP codes\n    \"\"\"\n    return (\n        pl.read_csv(\"zip_registry.csv\")\n        .filter((pl.col(\"state\") == state) &amp; (pl.col(\"city\") == city))\n        .select(\"zipcode\")\n    )\n</code></pre>"},{"location":"Helper/#src.Helper.state_county_to_zip_df","title":"<code>state_county_to_zip_df(state, county)</code>","text":"<p>Take in a state and county and return the ZIP code constituents of that county.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>the state</p> required <code>county</code> <code>str</code> <p>the county</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: DataFrame of ZIP codes</p> Source code in <code>src\\Helper.py</code> <pre><code>def state_county_to_zip_df(state: str, county: str) -&gt; pl.DataFrame:\n    \"\"\"Take in a state and county and return the ZIP code constituents of that county.\n\n    Args:\n        state (str): the state\n        county (str): the county\n\n    Returns:\n        pl.DataFrame: DataFrame of ZIP codes\n    \"\"\"\n    return (\n        pl.read_csv(\"zip_registry.csv\")\n        .filter((pl.col(\"state\") == state) &amp; (pl.col(\"county\") == county))\n        .select(\"zipcode\")\n    )\n</code></pre>"},{"location":"Helper/#src.Helper.zip_to_metro","title":"<code>zip_to_metro(zip)</code>","text":"<p>Find the Metropolitan Statistical Area name for the specified ZIP code.</p> <p>Parameters:</p> Name Type Description Default <code>zip</code> <code>int</code> <p>the ZIP code to look up</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the Metropolitan name. Is empty if the ZIP code is not a part of a Metropolitan Statistical Area</p> Source code in <code>src\\Helper.py</code> <pre><code>def zip_to_metro(zip: int) -&gt; str:\n    \"\"\"Find the Metropolitan Statistical Area name for the specified ZIP code.\n\n    Args:\n        zip (int): the ZIP code to look up\n\n    Returns:\n        str: the Metropolitan name. Is empty if the ZIP code is not a part of a Metropolitan Statistical Area\n    \"\"\"\n    df = pl.read_csv(\"./augmenting_data/master.csv\")\n\n    result = df.filter(df[\"ZIP\"] == zip)[\"METRO_NAME\"]\n\n    if len(result) &gt; 0:\n        return result[0]\n    else:\n        return \"    \"\n</code></pre>"},{"location":"RedfinListingScraper/","title":"RedfinListingScraper","text":""},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper","title":"<code>RedfinListingScraper</code>","text":"Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>class RedfinListingScraper:\n    def __init__(self, listing_url: str | None = None):\n        # probably going to trip someone up if they make another function. just trying to allow you to set on object creation or not set\n        self.listing_url = listing_url\n        self.soup = None\n        if listing_url is not None:\n            self.soup = self.make_soup(listing_url)\n            self.listing_url = listing_url\n        self.logger = Helper.logger\n\n    def make_soup(self, listing_url: str) -&gt; btfs:\n        \"\"\"Create `BeautifulSoup` object. Use output to set object's `self.soup`.\n\n        Args:\n            listing_url (str): listing URL\n\n        Returns:\n            btfs: the soup\n        \"\"\"\n        self.logger.debug(f\"Making soup for {listing_url = }\")\n        req = Helper.req_get_wrapper(listing_url)\n        req.raise_for_status()\n        req.encoding = \"utf-8\"\n        html = req.text\n        soup = btfs(html, \"html.parser\")\n        if soup is None:\n            self.logger.error(\n                f\"Soup is `None` for {listing_url = }, {req.status_code = }\"\n            )\n        return soup\n\n    def extract_heating_terms_from_list(self, terms_list: list[str]) -&gt; list[str]:\n        \"\"\"Extract a list of terms related to heating from the specified list.\n\n        Note:\n            Uses an include and exclude list, heating_related_patterns, exclude_terms, respectively.\n\n        Args:\n            terms_list (list[str]): list of terms\n\n        Returns:\n            list[str]: terms dealing with heating\n        \"\"\"\n\n        # here we just care that anything matches, not categorizing yet\n        heating_terms_list = []\n        # have a and not any(excluded_terms)?\n\n        for string in terms_list:\n            if any(\n                regex.findall(string) for regex in heating_related_patterns\n            ) and not any(regex.findall(string) for regex in exclude_terms):\n                heating_terms_list.append(string)\n\n        return heating_terms_list\n\n    def get_property_details(self) -&gt; element.PageElement | None:\n        \"\"\"Get the `propertyDetails-collapsible` div. This contains property details.\n\n        Returns:\n            element.PageElement | None: the div\n        \"\"\"\n        prop_details_container = self.soup.find(\"div\", id=\"propertyDetails-collapsible\")\n\n        if prop_details_container is None:\n            # TODO handle this\n            self.logger.info(\"Could not find property details\")\n            return None\n        prop_details = prop_details_container.find(\"div\", class_=\"amenities-container\")  # type: ignore\n        if prop_details is None:\n            self.logger.info(\"Details not under Details pane. this shouldnt happen\")\n            return None\n        # returns &lt;div class=\"amenities-container\"&gt;\n        return prop_details\n\n    def get_amenity_super_groups(\n        self, amenities_container_elements: element.PageElement\n    ) -&gt; list[str | element.PageElement | Any]:\n        \"\"\"Take in the `amenities-container` and return `super-group-content`s and their corresponding titles batched together.\n\n        Args:\n            amenities_container_elements (element.PageElement): The `amenities-container`\n\n        Returns:\n            _type_: title, contents of `super-group-content` divs\n        \"\"\"\n        title_content_pairs = itertools.batched(\n            amenities_container_elements.children, 2\n        )\n        return [[title.text, content] for title, content in title_content_pairs]\n\n    def get_probable_heating_amenity_groups(\n        self, super_group: element.PageElement\n    ) -&gt; list[Any]:\n        \"\"\"Take `super-group-content` div and return `amenity-group`s that likely have heating info.\n\n        Note:\n            Uses `self.heating_related_property_details_headers` for matching names\n        Args:\n            super_group (element.PageElement): a `super-group-content` div\n\n        Returns:\n            list[Any]: list of `amenity-group` divs\n        \"\"\"\n        list_of_amenity_groups = []\n        for amenity_group in super_group.children:\n            # check if the amenity group is related to heating\n            amenity_group_name = (\n                amenity_group.find(\"ul\")\n                .find(\"div\", class_=\"propertyDetailsHeader\")\n                .text\n            )\n            if any(\n                [\n                    regex.findall(amenity_group_name)\n                    for regex in heating_related_property_details_headers\n                ]\n            ):\n                list_of_amenity_groups.append(amenity_group)\n        return list_of_amenity_groups\n\n    def get_heating_terms_from_amenity_group(\n        self, amenity_group: element.PageElement\n    ) -&gt; list[str]:\n        \"\"\"Get a list of heating terms from the specified `amenity-group` div.\n\n        Args:\n            amenity_group (element.PageElement): the specified `amenity-group` div\n\n        Returns:\n            list[str]: list of heating terms\n        \"\"\"\n        terms = [\n            term_span.text\n            for term_span in amenity_group.find_all(\"span\", class_=\"entryItemContent\")\n        ]\n        return self.extract_heating_terms_from_list(terms)\n\n    def get_heating_terms_from_listing(\n        self, addr_and_listing_url: list[str]\n    ) -&gt; list[str]:\n        \"\"\"Find heating terms under the property details section of a Redfin listing.\n\n        Args:\n            addr_and_listing_url (str | None, optional): The listing url. Defaults to None.\n\n        Returns:\n            list[str]: list of heating terms\n        \"\"\"\n        addr, self.listing_url = addr_and_listing_url\n        # this is actually kinda stupid\n        self.soup = self.make_soup(self.listing_url)\n        all_items = []\n        details = self.get_property_details()\n        if details is not None:\n            amenity_super_groups = self.get_amenity_super_groups(details)\n            if amenity_super_groups is not None:\n                for title, amenity_group in amenity_super_groups:  # type: ignore\n                    self.logger.debug(f\"Getting terms from the super group: {title}\")\n                    heating_amenity_groups = self.get_probable_heating_amenity_groups(\n                        amenity_group  # type: ignore\n                    )\n                    for heating_amenity_group in heating_amenity_groups:\n                        all_items.extend(\n                            self.get_heating_terms_from_amenity_group(\n                                heating_amenity_group\n                            )\n                        )\n            else:\n                self.logger.debug(\n                    f\"No amenity super groups in valid details section. Investigate {self.listing_url}\"\n                )\n        else:\n            self.logger.info(f\"Could not find property details for {addr}.\")\n\n        if len(all_items) == 0:\n            self.logger.info(f\"{addr} did not have heating amenities.\")\n        else:\n            self.logger.info(f\"{addr} has heating amenities: {all_items}.\")\n\n        return all_items\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.extract_heating_terms_from_list","title":"<code>extract_heating_terms_from_list(terms_list)</code>","text":"<p>Extract a list of terms related to heating from the specified list.</p> Note <p>Uses an include and exclude list, heating_related_patterns, exclude_terms, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>terms_list</code> <code>list[str]</code> <p>list of terms</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: terms dealing with heating</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def extract_heating_terms_from_list(self, terms_list: list[str]) -&gt; list[str]:\n    \"\"\"Extract a list of terms related to heating from the specified list.\n\n    Note:\n        Uses an include and exclude list, heating_related_patterns, exclude_terms, respectively.\n\n    Args:\n        terms_list (list[str]): list of terms\n\n    Returns:\n        list[str]: terms dealing with heating\n    \"\"\"\n\n    # here we just care that anything matches, not categorizing yet\n    heating_terms_list = []\n    # have a and not any(excluded_terms)?\n\n    for string in terms_list:\n        if any(\n            regex.findall(string) for regex in heating_related_patterns\n        ) and not any(regex.findall(string) for regex in exclude_terms):\n            heating_terms_list.append(string)\n\n    return heating_terms_list\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.get_amenity_super_groups","title":"<code>get_amenity_super_groups(amenities_container_elements)</code>","text":"<p>Take in the <code>amenities-container</code> and return <code>super-group-content</code>s and their corresponding titles batched together.</p> <p>Parameters:</p> Name Type Description Default <code>amenities_container_elements</code> <code>PageElement</code> <p>The <code>amenities-container</code></p> required <p>Returns:</p> Name Type Description <code>_type_</code> <code>list[str | PageElement | Any]</code> <p>title, contents of <code>super-group-content</code> divs</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def get_amenity_super_groups(\n    self, amenities_container_elements: element.PageElement\n) -&gt; list[str | element.PageElement | Any]:\n    \"\"\"Take in the `amenities-container` and return `super-group-content`s and their corresponding titles batched together.\n\n    Args:\n        amenities_container_elements (element.PageElement): The `amenities-container`\n\n    Returns:\n        _type_: title, contents of `super-group-content` divs\n    \"\"\"\n    title_content_pairs = itertools.batched(\n        amenities_container_elements.children, 2\n    )\n    return [[title.text, content] for title, content in title_content_pairs]\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.get_heating_terms_from_amenity_group","title":"<code>get_heating_terms_from_amenity_group(amenity_group)</code>","text":"<p>Get a list of heating terms from the specified <code>amenity-group</code> div.</p> <p>Parameters:</p> Name Type Description Default <code>amenity_group</code> <code>PageElement</code> <p>the specified <code>amenity-group</code> div</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: list of heating terms</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def get_heating_terms_from_amenity_group(\n    self, amenity_group: element.PageElement\n) -&gt; list[str]:\n    \"\"\"Get a list of heating terms from the specified `amenity-group` div.\n\n    Args:\n        amenity_group (element.PageElement): the specified `amenity-group` div\n\n    Returns:\n        list[str]: list of heating terms\n    \"\"\"\n    terms = [\n        term_span.text\n        for term_span in amenity_group.find_all(\"span\", class_=\"entryItemContent\")\n    ]\n    return self.extract_heating_terms_from_list(terms)\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.get_heating_terms_from_listing","title":"<code>get_heating_terms_from_listing(addr_and_listing_url)</code>","text":"<p>Find heating terms under the property details section of a Redfin listing.</p> <p>Parameters:</p> Name Type Description Default <code>addr_and_listing_url</code> <code>str | None</code> <p>The listing url. Defaults to None.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: list of heating terms</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def get_heating_terms_from_listing(\n    self, addr_and_listing_url: list[str]\n) -&gt; list[str]:\n    \"\"\"Find heating terms under the property details section of a Redfin listing.\n\n    Args:\n        addr_and_listing_url (str | None, optional): The listing url. Defaults to None.\n\n    Returns:\n        list[str]: list of heating terms\n    \"\"\"\n    addr, self.listing_url = addr_and_listing_url\n    # this is actually kinda stupid\n    self.soup = self.make_soup(self.listing_url)\n    all_items = []\n    details = self.get_property_details()\n    if details is not None:\n        amenity_super_groups = self.get_amenity_super_groups(details)\n        if amenity_super_groups is not None:\n            for title, amenity_group in amenity_super_groups:  # type: ignore\n                self.logger.debug(f\"Getting terms from the super group: {title}\")\n                heating_amenity_groups = self.get_probable_heating_amenity_groups(\n                    amenity_group  # type: ignore\n                )\n                for heating_amenity_group in heating_amenity_groups:\n                    all_items.extend(\n                        self.get_heating_terms_from_amenity_group(\n                            heating_amenity_group\n                        )\n                    )\n        else:\n            self.logger.debug(\n                f\"No amenity super groups in valid details section. Investigate {self.listing_url}\"\n            )\n    else:\n        self.logger.info(f\"Could not find property details for {addr}.\")\n\n    if len(all_items) == 0:\n        self.logger.info(f\"{addr} did not have heating amenities.\")\n    else:\n        self.logger.info(f\"{addr} has heating amenities: {all_items}.\")\n\n    return all_items\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.get_probable_heating_amenity_groups","title":"<code>get_probable_heating_amenity_groups(super_group)</code>","text":"<p>Take <code>super-group-content</code> div and return <code>amenity-group</code>s that likely have heating info.</p> Note <p>Uses <code>self.heating_related_property_details_headers</code> for matching names</p> <p>Args:     super_group (element.PageElement): a <code>super-group-content</code> div</p> <p>Returns:</p> Type Description <code>list[Any]</code> <p>list[Any]: list of <code>amenity-group</code> divs</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def get_probable_heating_amenity_groups(\n    self, super_group: element.PageElement\n) -&gt; list[Any]:\n    \"\"\"Take `super-group-content` div and return `amenity-group`s that likely have heating info.\n\n    Note:\n        Uses `self.heating_related_property_details_headers` for matching names\n    Args:\n        super_group (element.PageElement): a `super-group-content` div\n\n    Returns:\n        list[Any]: list of `amenity-group` divs\n    \"\"\"\n    list_of_amenity_groups = []\n    for amenity_group in super_group.children:\n        # check if the amenity group is related to heating\n        amenity_group_name = (\n            amenity_group.find(\"ul\")\n            .find(\"div\", class_=\"propertyDetailsHeader\")\n            .text\n        )\n        if any(\n            [\n                regex.findall(amenity_group_name)\n                for regex in heating_related_property_details_headers\n            ]\n        ):\n            list_of_amenity_groups.append(amenity_group)\n    return list_of_amenity_groups\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.get_property_details","title":"<code>get_property_details()</code>","text":"<p>Get the <code>propertyDetails-collapsible</code> div. This contains property details.</p> <p>Returns:</p> Type Description <code>PageElement | None</code> <p>element.PageElement | None: the div</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def get_property_details(self) -&gt; element.PageElement | None:\n    \"\"\"Get the `propertyDetails-collapsible` div. This contains property details.\n\n    Returns:\n        element.PageElement | None: the div\n    \"\"\"\n    prop_details_container = self.soup.find(\"div\", id=\"propertyDetails-collapsible\")\n\n    if prop_details_container is None:\n        # TODO handle this\n        self.logger.info(\"Could not find property details\")\n        return None\n    prop_details = prop_details_container.find(\"div\", class_=\"amenities-container\")  # type: ignore\n    if prop_details is None:\n        self.logger.info(\"Details not under Details pane. this shouldnt happen\")\n        return None\n    # returns &lt;div class=\"amenities-container\"&gt;\n    return prop_details\n</code></pre>"},{"location":"RedfinListingScraper/#src.RedfinListingScraper.RedfinListingScraper.make_soup","title":"<code>make_soup(listing_url)</code>","text":"<p>Create <code>BeautifulSoup</code> object. Use output to set object's <code>self.soup</code>.</p> <p>Parameters:</p> Name Type Description Default <code>listing_url</code> <code>str</code> <p>listing URL</p> required <p>Returns:</p> Name Type Description <code>btfs</code> <code>BeautifulSoup</code> <p>the soup</p> Source code in <code>src\\RedfinListingScraper.py</code> <pre><code>def make_soup(self, listing_url: str) -&gt; btfs:\n    \"\"\"Create `BeautifulSoup` object. Use output to set object's `self.soup`.\n\n    Args:\n        listing_url (str): listing URL\n\n    Returns:\n        btfs: the soup\n    \"\"\"\n    self.logger.debug(f\"Making soup for {listing_url = }\")\n    req = Helper.req_get_wrapper(listing_url)\n    req.raise_for_status()\n    req.encoding = \"utf-8\"\n    html = req.text\n    soup = btfs(html, \"html.parser\")\n    if soup is None:\n        self.logger.error(\n            f\"Soup is `None` for {listing_url = }, {req.status_code = }\"\n        )\n    return soup\n</code></pre>"},{"location":"RedfinSearcher/","title":"RedfinSearcher","text":""},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher","title":"<code>RedfinSearcher</code>","text":"<p>Scrape Redfin and make use of their stingray API for retrieving housing information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rfs = RedfinSearcher()\n&gt;&gt;&gt; filters = rfs.generate_filters_path(...)\n&gt;&gt;&gt; rfs.set_filters_path(filters)\nshape(3,3)\n</code></pre> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class RedfinSearcher:\n    \"\"\"\n    Scrape Redfin and make use of their stingray API for retrieving housing information.\n\n    Examples:\n        &gt;&gt;&gt; rfs = RedfinSearcher()\n        &gt;&gt;&gt; filters = rfs.generate_filters_path(...)\n        &gt;&gt;&gt; rfs.set_filters_path(filters)\n        shape(3,3)\n    \"\"\"\n\n    def __init__(self, filters_path: str | None = None) -&gt; None:\n        self.REDFIN_BASE_URL = \"https://www.redfin.com\"\n        if filters_path is None:\n            self.filters_path = self.generate_filters_path(\n                sort=self.Sort.MOST_RECENTLY_SOLD,\n                property_type=self.PropertyType.HOUSE,\n                min_year_built=(datetime.now() - timedelta(weeks=52 * 5)).year,\n                include=self.Include.LAST_5_YEAR,\n                min_stories=self.Stories.ONE,\n            )\n        else:\n            self.filters_path = filters_path\n        self.LISTING_SCHEMA = {\n            \"LATITUDE\": pl.Float32,\n            \"LONGITUDE\": pl.Float32,\n            \"ADDRESS\": str,\n            \"CITY\": str,\n            \"STATE OR PROVINCE\": str,\n            \"ZIP OR POSTAL CODE\": pl.UInt16,\n            \"PRICE\": pl.UInt32,\n            \"YEAR BUILT\": pl.UInt16,\n            \"SQUARE FEET\": pl.UInt32,\n            \"HEATING AMENITIES\": list[str],\n        }\n        self.FULL_CSV_SCHEMA = {\n            \"SALE TYPE\": pl.Utf8,\n            \"SOLD DATE\": pl.Utf8,\n            \"PROPERTY TYPE\": pl.Utf8,\n            \"ADDRESS\": pl.Utf8,\n            \"CITY\": pl.Utf8,\n            \"STATE OR PROVINCE\": pl.Utf8,\n            \"ZIP OR POSTAL CODE\": pl.UInt16,\n            \"PRICE\": pl.UInt32,\n            \"BEDS\": pl.UInt8,\n            \"BATHS\": pl.Float32,\n            \"LOCATION\": pl.Utf8,\n            \"SQUARE FEET\": pl.UInt32,\n            \"LOT SIZE\": pl.UInt32,\n            \"YEAR BUILT\": pl.UInt16,\n            \"DAYS ON MARKET\": pl.UInt32,\n            \"$/SQUARE FEET\": pl.Float32,\n            \"HOA/MONTH\": pl.Float32,\n            \"STATUS\": pl.Utf8,\n            \"NEXT OPEN HOUSE START TIME\": pl.Utf8,\n            \"NEXT OPEN HOUSE END TIME\": pl.Utf8,\n            \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\": pl.Utf8,\n            \"SOURCE\": pl.Utf8,\n            \"MLS#\": pl.Utf8,\n            \"FAVORITE\": pl.Utf8,\n            \"INTERESTED\": pl.Utf8,\n            \"LATITUDE\": pl.Float32,\n            \"LONGITUDE\": pl.Float32,\n        }\n        self.CSV_SCHEMA = {\n            \"ADDRESS\": str,\n            \"CITY\": str,\n            \"STATE OR PROVINCE\": str,\n            \"YEAR BUILT\": pl.UInt16,\n            \"ZIP OR POSTAL CODE\": pl.UInt16,\n            \"PRICE\": pl.UInt32,\n            \"SQUARE FEET\": pl.UInt32,\n            \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\": str,\n            \"LATITUDE\": pl.Float32,\n            \"LONGITUDE\": pl.Float32,\n        }\n        self.logger = Helper.logger\n\n    class PropertyType(StrEnum):\n        \"\"\"Properties of the `property-type` filter.\"\"\"\n\n        HOUSE = \"house\"\n        CONDO = \"condo\"\n        TOWNHOUSE = \"townhouse\"\n        LAND = \"land\"\n        OTHER = \"other\"\n        MANUFACTURED = \"manufactured\"\n        COOP = \"co-op\"\n        MULTIFAMILY = \"multifamily\"\n\n    class Status(StrEnum):\n        \"\"\"Properties of the `status` filter.\n\n        Note:\n            Do not use in conjunction with `Include`. Use of the `status` filter on Redfin implies the house is for sale.\n            By default, Redfin searches for \\\"active\\\" and \\\"commingsoon\\\". This behavior is not replicated\n        \"\"\"\n\n        ACTIVE = \"active\"\n        COMINGSOON = \"comingsoon\"\n        CONTINGENT = \"contingent\"\n        PENDING = \"pending\"\n\n    class Include(StrEnum):\n        \"\"\"Properties of the `include` filter.\"\"\"\n\n        LAST_1_WEEK = \"sold-1wk\"\n        LAST_1_MONTH = \"sold-1mo\"\n        LAST_3_MONTHS = \"sold-3mo\"\n        LAST_6_MONTHS = \"sold-6mo\"\n        LAST_1_YEAR = \"sold-1yr\"\n        LAST_2_YEAR = \"sold-2yr\"\n        LAST_3_YEAR = \"sold-3yr\"\n        LAST_5_YEAR = \"sold-5yr\"\n\n    class Stories(StrEnum):\n        \"\"\"Properties of the `min-stories` filter.\"\"\"\n\n        ONE = \"1\"\n        TWO = \"2\"\n        THREE = \"3\"\n        FOUR = \"4\"\n        FIVE = \"5\"\n        TEN = \"10\"\n        FIFTEEN = \"15\"\n        TWENTY = \"20\"\n\n    class Sqft(StrEnum):\n        \"\"\"Properties of the `min-sqft` and `max-sqft` filter.\"\"\"\n\n        SEVEN_FIFTY = \"750\"\n        THOU = \"1K\"\n        THOU_1 = \"1.1k\"\n        THOU_2 = \"1.2k\"\n        THOU_3 = \"1.3k\"\n        THOU_4 = \"1.4k\"\n        THOU_5 = \"1.5k\"\n        THOU_6 = \"1.6k\"\n        THOU_7 = \"1.7k\"\n        THOU_8 = \"1.8k\"\n        THOU_9 = \"1.9k\"\n        TWO_THOU = \"2k\"\n        TWO_THOU_250 = \"2.25k\"\n        TWO_THOU_500 = \"2.5k\"\n        TWO_THOU_750 = \"2.75k\"\n        THREE_THOU = \"3k\"\n        FOUR_THOU = \"4k\"\n        FIVE_THOU = \"5k\"\n        SEVEN_THOU_500 = \"7.5k\"\n        TEN_THOU = \"10k\"\n\n    class Sort(StrEnum):\n        \"\"\"Properties of the `sort` filter.\n\n        Note:\n            Filters `NEWEST` and `MOST_RECENTLY_SOLD` are mutually exclusive.\n        \"\"\"\n\n        # for sale only\n        NEWEST = \"lo-days\"\n        # sold only\n        MOST_RECENTLY_SOLD = \"hi-sale-date\"\n        # both\n        LOW__TO_HIGH_PRICE = \"lo-price\"\n        HIGH_TO_LOW_PRICE = \"hi-price\"\n        SQFT = \"hi-sqft\"\n        LOT_SIZE = \"hi-lot-sqf\"\n        PRICE_PER_SQFT = \"lo-dollarsqft\"\n\n    def set_filters_path(self, filters_path: str) -&gt; None:\n        \"\"\"Set the search filters for all searches made with this RedfinSearcher object.\n\n        Args:\n            filters_path (str): the URL path to search with\n        \"\"\"\n        self.logger.debug(f\"Setting filters to: {filters_path}\")\n        self.filters_path = filters_path\n\n    def generate_area_path(self, zip_code_or_city_and_state_or_address: str) -&gt; str:\n        \"\"\"Generate the path for the specified location. Redfin uses proprietary numbers to identify cities. This makes a call to their\n        stingray API to get the translation.\n\n        Args:\n            zip_code_or_city_and_state_or_address (str): the location. Either a zip code, or a city and state, or an address\n\n        Returns:\n            path: the path, for example \"/zipcode/01609\"\n        \"\"\"\n        if (\n            len(zip_code_or_city_and_state_or_address) == 5\n            and zip_code_or_city_and_state_or_address.isdigit()\n        ):\n            return f\"/zipcode/{zip_code_or_city_and_state_or_address}\"\n\n        # Cache this to a json or something\n        path_url = (\n            f\"{Helper.get_redfin_url_path(zip_code_or_city_and_state_or_address)}\"\n        )\n        return path_url\n\n    @staticmethod\n    def generate_filters_path(**kwargs) -&gt; str:\n        \"\"\"Generate the path for the specified filters.\n\n        Note:\n            When using `include`, you cannot use: `status` TODO\n\n            When searching by f, you cannot use: TODO\n\n        Available filters:\n            * `include`\n            * `property-type`\n            * `min-beds`\n            * `max-beds`\n            * `min-baths`\n            * `max-baths`\n            * `min-year-built`\n            * `max-year-built`\n            * `status`\n            * `min-price`\n            * `max-price`\n            * `sort`\n            * `exclude-age-restricted`\n            * `is-green`\n            * `fireplace`\n            * `min-stories`\n            * `min-sqft`\n\n        Examples:\n            For generating a filter string that has a filter with 1 value:\n\n            &gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=PropertyType.HOUSE)\n            \"/filter/min-sqft=1k,property-type=house\"\n\n            For generating a filter string that has a filter with multiple values:\n\n            &gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=[PropertyType.HOUSE, PropertyType.TOWNHOUSE])\n            \"/filter/min-sqft=1k,property-type=house+townhouse\"\n\n        Returns:\n            str: the url filter string\n        \"\"\"\n        selected_filters = []\n\n        # can do additional checks if wanted, treat param names as filter words\n        for key, value in kwargs.items():\n            if isinstance(value, list):\n                selected_filters.append(f'{key.replace(\"_\",\"-\")}={\"+\".join(value)}')\n            else:\n                selected_filters.append(f'{key.replace(\"_\",\"-\")}={value}')\n\n        return f'/filter/{\",\".join(selected_filters)}'\n\n    def df_from_search_page_csv(self, url: str) -&gt; pl.DataFrame | None:\n        \"\"\"Return a DataFrame of the contents scraped from the \\\"Download all\\\" button on the specified search page URL.\n\n        Note:\n            The schema of this DataFrame is listed in `RedfinSearcher.CSV_SCHEMA`.\n\n        Args:\n            url (str): the URL of the search page\n\n        Returns:\n            pl.DataFrame | None: the DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available\n        \"\"\"\n        req = Helper.req_get_wrapper(url)\n        req.raise_for_status()\n\n        html = req.content\n        soup = btfs(html, \"html.parser\")\n        download_button_id = \"download-and-save\"\n        download_link_tag = soup.find(\"a\", id=download_button_id)\n        if download_link_tag is None:\n            # should be handled in caller\n            # randomly gives this error. investigate, if truly just random, retry in one second\n            self.logger.debug(\n                f\"Finding download button failed for {url = }. {req.status_code = }, {len(html) = }\"\n            )\n            raise TypeError(\n                \"Could not find CSV download. Check if the html downloaded is correct, or if the download button id has changed\"\n            )\n\n        download_link = download_link_tag.get(\"href\")  # type: ignore\n\n        match download_link:\n            case None:\n                raise KeyError(\n                    f\"&lt;a&gt; tag with id {download_button_id} does not exist. Has the HTML id changed?\"\n                )\n            case list():\n                raise KeyError(\n                    f\"&lt;a&gt; tag with id {download_button_id} has multiple values\"\n                )\n\n        return pl.read_csv(\n            source=f\"{self.REDFIN_BASE_URL}{download_link}\", dtypes=self.FULL_CSV_SCHEMA\n        ).select(\n            \"ADDRESS\",\n            \"CITY\",\n            \"STATE OR PROVINCE\",\n            \"YEAR BUILT\",\n            \"ZIP OR POSTAL CODE\",\n            \"PRICE\",\n            \"SQUARE FEET\",\n            \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\",\n            \"LATITUDE\",\n            \"LONGITUDE\",\n        )\n\n    def zips_to_search_page_csvs(self, zip_codes: list[int]) -&gt; pl.DataFrame | None:\n        \"\"\"Return a DataFrame produced by concatenating all of the specified ZIP codes' search page CSVs.\n\n        Args:\n            zip_codes (list[int]): list of ZIP codes to search\n\n        Returns:\n            pl.DataFrame | None: the concatenated DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available\n        \"\"\"\n        formatted_zip_codes = [f\"{zip_code:0{5}}\" for zip_code in zip_codes]\n        list_of_csv_dfs = []\n\n        for zip_code in formatted_zip_codes:\n            search_page_url = f\"{self.REDFIN_BASE_URL}{self.generate_area_path(zip_code)}{self.filters_path}\"\n            self.logger.debug(f\"searching zip code with {search_page_url = }\")\n            try:\n                # this is the only place where this error should pop up. if a zip is invalid,\n                # return none and handle in caller. an example is the zip 56998, which is just a\n                # USPS distribution center in D.C\n                # should df_from_search_page be returning none\n                redfin_csv_df = self.df_from_search_page_csv(search_page_url)\n            except requests.HTTPError as e:\n                #! this also gave random error\n                self.logger.error(\n                    f\"{search_page_url = } gave an invalid zip code (possible its something else) error.\\n{e}\"\n                )\n                return None\n\n            if redfin_csv_df is None:\n                self.logger.info(\n                    f\"The download link for {zip_code}'s search page is not available\"\n                )\n                continue\n\n            list_of_csv_dfs.append(redfin_csv_df)\n        return pl.concat(list_of_csv_dfs)\n\n    def load_house_attributes_from_metro(\n        self, metro_name: str, filters_path: str | None = None\n    ) -&gt; pl.DataFrame:\n        \"\"\"Create a DataFrame of a metropolitan's available houses' attributes, including heating information.\n\n        Note:\n            The process is as follows:\n            * Convert a Metropolitan Statistical Area name into its constituent ZIP codes\n            * For each ZIP code, search Redfin with filters and collect listing results. (ZIP codes are searched to ensure maximal data collection, as Redfin only returns (9 pages * 40 listings) 360 entries per search.)\n            * For each listing collected, creates a DataFrame of house attributes, such as location and heating amenities.\n\n        Args:\n            metro_name (str): a Metropolitan Statistical Area name\n            filters_path (str): a filters path to search with\n\n        Returns:\n            pl.DataFrame: DataFrame of collected listing information\n        \"\"\"\n        if filters_path is not None:\n            self.logger.info(\n                f\"Filter path was supplied, overwriting filter string {Helper.ASCIIColors.YELLOW}{self.filters_path}{Helper.ASCIIColors.RESET} with {Helper.ASCIIColors.YELLOW}{filters_path}{Helper.ASCIIColors.RESET}\"\n            )\n            self.set_filters_path(filters_path)\n            self.logger.debug(f\"Metro is using filter string: {self.filters_path}\")\n        zip_codes = Helper.metro_name_to_zip_code_list(metro_name)\n\n        if len(zip_codes) == 0:\n            self.logger.debug(\"no zip codes returned from metro name conversion\")\n            return pl.DataFrame(schema=self.LISTING_SCHEMA)\n\n        zip_code_search_page_csvs_df = self.zips_to_search_page_csvs(zip_codes)\n\n        if zip_code_search_page_csvs_df is None:\n            self.logger.info(\"Supplied zip codes do not have listings. Relax filters?\")\n            return pl.DataFrame(schema=self.LISTING_SCHEMA)\n\n        # house attribs check\n        return self.listing_attributes_from_search_page_csv(\n            zip_code_search_page_csvs_df\n        )\n\n    def listing_attributes_from_search_page_csv(\n        self, search_page_csvs: pl.DataFrame\n    ) -&gt; pl.DataFrame:\n        \"\"\"Get house attributes the URLS supplied by the specified DataFrame, given that it has a column with the name \"URL (SEE ht...)\".\n\n        Args:\n            search_page_csvs (pl.DataFrame): search page CSV DataFrame\n\n        Returns:\n            pl.DataFrame: the DataFrame. Is empty if no house has heating data\n        \"\"\"\n        url_col_name = \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\"\n        self.logger.info(\"Starting lookups on listing URLS\")\n        rls = RedfinListingScraper()\n        # might make two function argument to pass in address, so that logs can happen inside the amenities scrap func\n        # if cant make two function arg, can build two cols into list and pass the list using\n        return (\n            search_page_csvs.with_columns(\n                (pl.concat_list([pl.col(\"ADDRESS\"), pl.col(url_col_name)]))\n                .map_elements(rls.get_heating_terms_from_listing)\n                .cast(pl.List(pl.Utf8))\n                .alias(\"HEATING AMENITIES\")\n            )\n            # .filter(pl.col(\"HEATING AMENITIES\").list.len().gt(pl.lit(0)))\n            .drop(url_col_name)\n        )\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.Include","title":"<code>Include</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>include</code> filter.</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class Include(StrEnum):\n    \"\"\"Properties of the `include` filter.\"\"\"\n\n    LAST_1_WEEK = \"sold-1wk\"\n    LAST_1_MONTH = \"sold-1mo\"\n    LAST_3_MONTHS = \"sold-3mo\"\n    LAST_6_MONTHS = \"sold-6mo\"\n    LAST_1_YEAR = \"sold-1yr\"\n    LAST_2_YEAR = \"sold-2yr\"\n    LAST_3_YEAR = \"sold-3yr\"\n    LAST_5_YEAR = \"sold-5yr\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.PropertyType","title":"<code>PropertyType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>property-type</code> filter.</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class PropertyType(StrEnum):\n    \"\"\"Properties of the `property-type` filter.\"\"\"\n\n    HOUSE = \"house\"\n    CONDO = \"condo\"\n    TOWNHOUSE = \"townhouse\"\n    LAND = \"land\"\n    OTHER = \"other\"\n    MANUFACTURED = \"manufactured\"\n    COOP = \"co-op\"\n    MULTIFAMILY = \"multifamily\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.Sort","title":"<code>Sort</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>sort</code> filter.</p> Note <p>Filters <code>NEWEST</code> and <code>MOST_RECENTLY_SOLD</code> are mutually exclusive.</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class Sort(StrEnum):\n    \"\"\"Properties of the `sort` filter.\n\n    Note:\n        Filters `NEWEST` and `MOST_RECENTLY_SOLD` are mutually exclusive.\n    \"\"\"\n\n    # for sale only\n    NEWEST = \"lo-days\"\n    # sold only\n    MOST_RECENTLY_SOLD = \"hi-sale-date\"\n    # both\n    LOW__TO_HIGH_PRICE = \"lo-price\"\n    HIGH_TO_LOW_PRICE = \"hi-price\"\n    SQFT = \"hi-sqft\"\n    LOT_SIZE = \"hi-lot-sqf\"\n    PRICE_PER_SQFT = \"lo-dollarsqft\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.Sqft","title":"<code>Sqft</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>min-sqft</code> and <code>max-sqft</code> filter.</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class Sqft(StrEnum):\n    \"\"\"Properties of the `min-sqft` and `max-sqft` filter.\"\"\"\n\n    SEVEN_FIFTY = \"750\"\n    THOU = \"1K\"\n    THOU_1 = \"1.1k\"\n    THOU_2 = \"1.2k\"\n    THOU_3 = \"1.3k\"\n    THOU_4 = \"1.4k\"\n    THOU_5 = \"1.5k\"\n    THOU_6 = \"1.6k\"\n    THOU_7 = \"1.7k\"\n    THOU_8 = \"1.8k\"\n    THOU_9 = \"1.9k\"\n    TWO_THOU = \"2k\"\n    TWO_THOU_250 = \"2.25k\"\n    TWO_THOU_500 = \"2.5k\"\n    TWO_THOU_750 = \"2.75k\"\n    THREE_THOU = \"3k\"\n    FOUR_THOU = \"4k\"\n    FIVE_THOU = \"5k\"\n    SEVEN_THOU_500 = \"7.5k\"\n    TEN_THOU = \"10k\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.Status","title":"<code>Status</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>status</code> filter.</p> Note <p>Do not use in conjunction with <code>Include</code>. Use of the <code>status</code> filter on Redfin implies the house is for sale. By default, Redfin searches for \"active\" and \"commingsoon\". This behavior is not replicated</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class Status(StrEnum):\n    \"\"\"Properties of the `status` filter.\n\n    Note:\n        Do not use in conjunction with `Include`. Use of the `status` filter on Redfin implies the house is for sale.\n        By default, Redfin searches for \\\"active\\\" and \\\"commingsoon\\\". This behavior is not replicated\n    \"\"\"\n\n    ACTIVE = \"active\"\n    COMINGSOON = \"comingsoon\"\n    CONTINGENT = \"contingent\"\n    PENDING = \"pending\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.Stories","title":"<code>Stories</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Properties of the <code>min-stories</code> filter.</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>class Stories(StrEnum):\n    \"\"\"Properties of the `min-stories` filter.\"\"\"\n\n    ONE = \"1\"\n    TWO = \"2\"\n    THREE = \"3\"\n    FOUR = \"4\"\n    FIVE = \"5\"\n    TEN = \"10\"\n    FIFTEEN = \"15\"\n    TWENTY = \"20\"\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.df_from_search_page_csv","title":"<code>df_from_search_page_csv(url)</code>","text":"<p>Return a DataFrame of the contents scraped from the \"Download all\" button on the specified search page URL.</p> Note <p>The schema of this DataFrame is listed in <code>RedfinSearcher.CSV_SCHEMA</code>.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>the URL of the search page</p> required <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>pl.DataFrame | None: the DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def df_from_search_page_csv(self, url: str) -&gt; pl.DataFrame | None:\n    \"\"\"Return a DataFrame of the contents scraped from the \\\"Download all\\\" button on the specified search page URL.\n\n    Note:\n        The schema of this DataFrame is listed in `RedfinSearcher.CSV_SCHEMA`.\n\n    Args:\n        url (str): the URL of the search page\n\n    Returns:\n        pl.DataFrame | None: the DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available\n    \"\"\"\n    req = Helper.req_get_wrapper(url)\n    req.raise_for_status()\n\n    html = req.content\n    soup = btfs(html, \"html.parser\")\n    download_button_id = \"download-and-save\"\n    download_link_tag = soup.find(\"a\", id=download_button_id)\n    if download_link_tag is None:\n        # should be handled in caller\n        # randomly gives this error. investigate, if truly just random, retry in one second\n        self.logger.debug(\n            f\"Finding download button failed for {url = }. {req.status_code = }, {len(html) = }\"\n        )\n        raise TypeError(\n            \"Could not find CSV download. Check if the html downloaded is correct, or if the download button id has changed\"\n        )\n\n    download_link = download_link_tag.get(\"href\")  # type: ignore\n\n    match download_link:\n        case None:\n            raise KeyError(\n                f\"&lt;a&gt; tag with id {download_button_id} does not exist. Has the HTML id changed?\"\n            )\n        case list():\n            raise KeyError(\n                f\"&lt;a&gt; tag with id {download_button_id} has multiple values\"\n            )\n\n    return pl.read_csv(\n        source=f\"{self.REDFIN_BASE_URL}{download_link}\", dtypes=self.FULL_CSV_SCHEMA\n    ).select(\n        \"ADDRESS\",\n        \"CITY\",\n        \"STATE OR PROVINCE\",\n        \"YEAR BUILT\",\n        \"ZIP OR POSTAL CODE\",\n        \"PRICE\",\n        \"SQUARE FEET\",\n        \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\",\n        \"LATITUDE\",\n        \"LONGITUDE\",\n    )\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.generate_area_path","title":"<code>generate_area_path(zip_code_or_city_and_state_or_address)</code>","text":"<p>Generate the path for the specified location. Redfin uses proprietary numbers to identify cities. This makes a call to their stingray API to get the translation.</p> <p>Parameters:</p> Name Type Description Default <code>zip_code_or_city_and_state_or_address</code> <code>str</code> <p>the location. Either a zip code, or a city and state, or an address</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>the path, for example \"/zipcode/01609\"</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def generate_area_path(self, zip_code_or_city_and_state_or_address: str) -&gt; str:\n    \"\"\"Generate the path for the specified location. Redfin uses proprietary numbers to identify cities. This makes a call to their\n    stingray API to get the translation.\n\n    Args:\n        zip_code_or_city_and_state_or_address (str): the location. Either a zip code, or a city and state, or an address\n\n    Returns:\n        path: the path, for example \"/zipcode/01609\"\n    \"\"\"\n    if (\n        len(zip_code_or_city_and_state_or_address) == 5\n        and zip_code_or_city_and_state_or_address.isdigit()\n    ):\n        return f\"/zipcode/{zip_code_or_city_and_state_or_address}\"\n\n    # Cache this to a json or something\n    path_url = (\n        f\"{Helper.get_redfin_url_path(zip_code_or_city_and_state_or_address)}\"\n    )\n    return path_url\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.generate_filters_path","title":"<code>generate_filters_path(**kwargs)</code>  <code>staticmethod</code>","text":"<p>Generate the path for the specified filters.</p> Note <p>When using <code>include</code>, you cannot use: <code>status</code> TODO</p> <p>When searching by f, you cannot use: TODO</p> Available filters <ul> <li><code>include</code></li> <li><code>property-type</code></li> <li><code>min-beds</code></li> <li><code>max-beds</code></li> <li><code>min-baths</code></li> <li><code>max-baths</code></li> <li><code>min-year-built</code></li> <li><code>max-year-built</code></li> <li><code>status</code></li> <li><code>min-price</code></li> <li><code>max-price</code></li> <li><code>sort</code></li> <li><code>exclude-age-restricted</code></li> <li><code>is-green</code></li> <li><code>fireplace</code></li> <li><code>min-stories</code></li> <li><code>min-sqft</code></li> </ul> <p>Examples:</p> <p>For generating a filter string that has a filter with 1 value:</p> <pre><code>&gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=PropertyType.HOUSE)\n\"/filter/min-sqft=1k,property-type=house\"\n</code></pre> <p>For generating a filter string that has a filter with multiple values:</p> <pre><code>&gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=[PropertyType.HOUSE, PropertyType.TOWNHOUSE])\n\"/filter/min-sqft=1k,property-type=house+townhouse\"\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the url filter string</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>@staticmethod\ndef generate_filters_path(**kwargs) -&gt; str:\n    \"\"\"Generate the path for the specified filters.\n\n    Note:\n        When using `include`, you cannot use: `status` TODO\n\n        When searching by f, you cannot use: TODO\n\n    Available filters:\n        * `include`\n        * `property-type`\n        * `min-beds`\n        * `max-beds`\n        * `min-baths`\n        * `max-baths`\n        * `min-year-built`\n        * `max-year-built`\n        * `status`\n        * `min-price`\n        * `max-price`\n        * `sort`\n        * `exclude-age-restricted`\n        * `is-green`\n        * `fireplace`\n        * `min-stories`\n        * `min-sqft`\n\n    Examples:\n        For generating a filter string that has a filter with 1 value:\n\n        &gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=PropertyType.HOUSE)\n        \"/filter/min-sqft=1k,property-type=house\"\n\n        For generating a filter string that has a filter with multiple values:\n\n        &gt;&gt;&gt; generate_filters_path(min-sqft=Sqft.THOU, property_type=[PropertyType.HOUSE, PropertyType.TOWNHOUSE])\n        \"/filter/min-sqft=1k,property-type=house+townhouse\"\n\n    Returns:\n        str: the url filter string\n    \"\"\"\n    selected_filters = []\n\n    # can do additional checks if wanted, treat param names as filter words\n    for key, value in kwargs.items():\n        if isinstance(value, list):\n            selected_filters.append(f'{key.replace(\"_\",\"-\")}={\"+\".join(value)}')\n        else:\n            selected_filters.append(f'{key.replace(\"_\",\"-\")}={value}')\n\n    return f'/filter/{\",\".join(selected_filters)}'\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.listing_attributes_from_search_page_csv","title":"<code>listing_attributes_from_search_page_csv(search_page_csvs)</code>","text":"<p>Get house attributes the URLS supplied by the specified DataFrame, given that it has a column with the name \"URL (SEE ht...)\".</p> <p>Parameters:</p> Name Type Description Default <code>search_page_csvs</code> <code>DataFrame</code> <p>search page CSV DataFrame</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: the DataFrame. Is empty if no house has heating data</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def listing_attributes_from_search_page_csv(\n    self, search_page_csvs: pl.DataFrame\n) -&gt; pl.DataFrame:\n    \"\"\"Get house attributes the URLS supplied by the specified DataFrame, given that it has a column with the name \"URL (SEE ht...)\".\n\n    Args:\n        search_page_csvs (pl.DataFrame): search page CSV DataFrame\n\n    Returns:\n        pl.DataFrame: the DataFrame. Is empty if no house has heating data\n    \"\"\"\n    url_col_name = \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\"\n    self.logger.info(\"Starting lookups on listing URLS\")\n    rls = RedfinListingScraper()\n    # might make two function argument to pass in address, so that logs can happen inside the amenities scrap func\n    # if cant make two function arg, can build two cols into list and pass the list using\n    return (\n        search_page_csvs.with_columns(\n            (pl.concat_list([pl.col(\"ADDRESS\"), pl.col(url_col_name)]))\n            .map_elements(rls.get_heating_terms_from_listing)\n            .cast(pl.List(pl.Utf8))\n            .alias(\"HEATING AMENITIES\")\n        )\n        # .filter(pl.col(\"HEATING AMENITIES\").list.len().gt(pl.lit(0)))\n        .drop(url_col_name)\n    )\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.load_house_attributes_from_metro","title":"<code>load_house_attributes_from_metro(metro_name, filters_path=None)</code>","text":"<p>Create a DataFrame of a metropolitan's available houses' attributes, including heating information.</p> Note <p>The process is as follows: * Convert a Metropolitan Statistical Area name into its constituent ZIP codes * For each ZIP code, search Redfin with filters and collect listing results. (ZIP codes are searched to ensure maximal data collection, as Redfin only returns (9 pages * 40 listings) 360 entries per search.) * For each listing collected, creates a DataFrame of house attributes, such as location and heating amenities.</p> <p>Parameters:</p> Name Type Description Default <code>metro_name</code> <code>str</code> <p>a Metropolitan Statistical Area name</p> required <code>filters_path</code> <code>str</code> <p>a filters path to search with</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: DataFrame of collected listing information</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def load_house_attributes_from_metro(\n    self, metro_name: str, filters_path: str | None = None\n) -&gt; pl.DataFrame:\n    \"\"\"Create a DataFrame of a metropolitan's available houses' attributes, including heating information.\n\n    Note:\n        The process is as follows:\n        * Convert a Metropolitan Statistical Area name into its constituent ZIP codes\n        * For each ZIP code, search Redfin with filters and collect listing results. (ZIP codes are searched to ensure maximal data collection, as Redfin only returns (9 pages * 40 listings) 360 entries per search.)\n        * For each listing collected, creates a DataFrame of house attributes, such as location and heating amenities.\n\n    Args:\n        metro_name (str): a Metropolitan Statistical Area name\n        filters_path (str): a filters path to search with\n\n    Returns:\n        pl.DataFrame: DataFrame of collected listing information\n    \"\"\"\n    if filters_path is not None:\n        self.logger.info(\n            f\"Filter path was supplied, overwriting filter string {Helper.ASCIIColors.YELLOW}{self.filters_path}{Helper.ASCIIColors.RESET} with {Helper.ASCIIColors.YELLOW}{filters_path}{Helper.ASCIIColors.RESET}\"\n        )\n        self.set_filters_path(filters_path)\n        self.logger.debug(f\"Metro is using filter string: {self.filters_path}\")\n    zip_codes = Helper.metro_name_to_zip_code_list(metro_name)\n\n    if len(zip_codes) == 0:\n        self.logger.debug(\"no zip codes returned from metro name conversion\")\n        return pl.DataFrame(schema=self.LISTING_SCHEMA)\n\n    zip_code_search_page_csvs_df = self.zips_to_search_page_csvs(zip_codes)\n\n    if zip_code_search_page_csvs_df is None:\n        self.logger.info(\"Supplied zip codes do not have listings. Relax filters?\")\n        return pl.DataFrame(schema=self.LISTING_SCHEMA)\n\n    # house attribs check\n    return self.listing_attributes_from_search_page_csv(\n        zip_code_search_page_csvs_df\n    )\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.set_filters_path","title":"<code>set_filters_path(filters_path)</code>","text":"<p>Set the search filters for all searches made with this RedfinSearcher object.</p> <p>Parameters:</p> Name Type Description Default <code>filters_path</code> <code>str</code> <p>the URL path to search with</p> required Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def set_filters_path(self, filters_path: str) -&gt; None:\n    \"\"\"Set the search filters for all searches made with this RedfinSearcher object.\n\n    Args:\n        filters_path (str): the URL path to search with\n    \"\"\"\n    self.logger.debug(f\"Setting filters to: {filters_path}\")\n    self.filters_path = filters_path\n</code></pre>"},{"location":"RedfinSearcher/#src.RedfinSearcher.RedfinSearcher.zips_to_search_page_csvs","title":"<code>zips_to_search_page_csvs(zip_codes)</code>","text":"<p>Return a DataFrame produced by concatenating all of the specified ZIP codes' search page CSVs.</p> <p>Parameters:</p> Name Type Description Default <code>zip_codes</code> <code>list[int]</code> <p>list of ZIP codes to search</p> required <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>pl.DataFrame | None: the concatenated DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available</p> Source code in <code>src\\RedfinSearcher.py</code> <pre><code>def zips_to_search_page_csvs(self, zip_codes: list[int]) -&gt; pl.DataFrame | None:\n    \"\"\"Return a DataFrame produced by concatenating all of the specified ZIP codes' search page CSVs.\n\n    Args:\n        zip_codes (list[int]): list of ZIP codes to search\n\n    Returns:\n        pl.DataFrame | None: the concatenated DataFrame. Is empty if there are no listings for the given filters. Is None if the CSV download link is not available\n    \"\"\"\n    formatted_zip_codes = [f\"{zip_code:0{5}}\" for zip_code in zip_codes]\n    list_of_csv_dfs = []\n\n    for zip_code in formatted_zip_codes:\n        search_page_url = f\"{self.REDFIN_BASE_URL}{self.generate_area_path(zip_code)}{self.filters_path}\"\n        self.logger.debug(f\"searching zip code with {search_page_url = }\")\n        try:\n            # this is the only place where this error should pop up. if a zip is invalid,\n            # return none and handle in caller. an example is the zip 56998, which is just a\n            # USPS distribution center in D.C\n            # should df_from_search_page be returning none\n            redfin_csv_df = self.df_from_search_page_csv(search_page_url)\n        except requests.HTTPError as e:\n            #! this also gave random error\n            self.logger.error(\n                f\"{search_page_url = } gave an invalid zip code (possible its something else) error.\\n{e}\"\n            )\n            return None\n\n        if redfin_csv_df is None:\n            self.logger.info(\n                f\"The download link for {zip_code}'s search page is not available\"\n            )\n            continue\n\n        list_of_csv_dfs.append(redfin_csv_df)\n    return pl.concat(list_of_csv_dfs)\n</code></pre>"},{"location":"UtilitiesPriceData/","title":"UtilitiesPriceData","text":""},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever","title":"<code>EIADataRetriever</code>","text":"Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>class EIADataRetriever:\n    # Electricity:\n    #   can get by month per state\n    # Propane and Heating oil:\n    #   *per month is per heating month*\n    #   can get by month per PAD, or by us average\n    #   can get by week per tracked state\n    class EnergyTypes(Enum):\n        PROPANE = 1\n        NATURAL_GAS = 2\n        ELECTRICITY = 3\n        HEATING_OIL = 4\n\n    class PetroleumProductTypes(StrEnum):\n        NATURAL_GAS = \"EPG0\"\n        PROPANE = \"EPLLPA\"\n        HEATING_OIL = \"EPD2F\"\n\n    class FuelBTUConversion(Enum):\n        # https://www.edf.org/sites/default/files/10071_EDF_BottomBarrel_Ch3.pdf\n        # https://www.eia.gov/energyexplained/units-and-calculators/british-thermal-units.php\n        # https://www.eia.gov/energyexplained/units-and-calculators/\n        NO1_OIL_BTU_PER_GAL = 135000\n        NO2_OIL_BTU_PER_GAL = 140000\n        NO4_OIL_BTU_PER_GAL = 146000\n        NO5_OIL_BTU_PER_GAL = 144500\n        NO6_OIL_BTU_PER_GAL = 150000\n        HEATING_OIL_BTU_PER_GAL = 138500\n        ELECTRICITY_BTU_PER_KWH = 3412.14\n        # 1000 cubic feet\n        NG_BTU_PER_MCT = 1036\n        NG_BTU_PER_THERM = 100000\n        PROPANE_BTU_PER_GAL = 91452\n        WOOD_BTU_PER_CORD = 20000000\n\n    def __init__(self):\n        self.eia_base_url = \"https://api.eia.gov/v2\"\n        self.api_key = os.getenv(\"EIA_API_KEY\")\n\n    # normalize prices\n    #!this should be failing?\n    def _price_per_btu_converter(\n        self, energy_price_dict: dict\n    ) -&gt; dict[str, str | EnergyTypes | float]:\n        \"\"\"Convert an energy source's price per quantity into price per BTU.\n\n        Args:\n            energy_source (_type_): energy source json\n\n        Returns:\n            dict: new dictionary with btu centric pricing\n        \"\"\"\n        # https://portfoliomanager.energystar.gov/pdf/reference/Thermal%20Conversions.pdf\n        # Natural gas: $13.86 per thousand cubic feet /1.036 million Btu per thousand cubic feet = $13.38 per million Btu\n        #! currently doesn't take into account efficiency: make new function based on burner type/ end usage type\n        #! double check money units\n        btu_dict = {}\n        factor = 1\n        CENTS_IN_DOLLAR = 100\n        match energy_price_dict.get(\"type\"):\n            case self.EnergyTypes.PROPANE:\n                factor = self.FuelBTUConversion.PROPANE_BTU_PER_GAL\n            case self.EnergyTypes.NATURAL_GAS:\n                factor = self.FuelBTUConversion.NG_BTU_PER_MCT\n            case self.EnergyTypes.ELECTRICITY:\n                factor = (\n                    self.FuelBTUConversion.ELECTRICITY_BTU_PER_KWH.value\n                    / CENTS_IN_DOLLAR\n                )\n            case self.EnergyTypes.HEATING_OIL:\n                factor = self.FuelBTUConversion.HEATING_OIL_BTU_PER_GAL\n\n        for key, value in energy_price_dict.items():\n            if key in [\"type\", \"state\"]:\n                btu_dict[key] = value\n                continue\n            btu_dict[key] = value / factor\n\n        return btu_dict\n\n    # api to dict handler Helpers\n    def price_dict_to_clean_dict(\n        self, eia_json: dict, energy_type: EnergyTypes, state: str\n    ) -&gt; dict[str, str | EnergyTypes | float]:\n        \"\"\"Clean JSON data returned by EIA's API.\n\n        Args:\n            eia_json (_type_): the dirty JSON\n\n        Returns:\n            dict: cleaned JSON with state and energy type\n        \"\"\"\n        # price key is different for electricity\n        accessor = \"value\"\n        if \"product\" not in eia_json[\"response\"][\"data\"][0]:\n            accessor = \"price\"\n\n        result_dict = {\n            entry[\"period\"]: entry[f\"{accessor}\"]\n            for entry in eia_json[\"response\"][\"data\"]\n        }\n        result_dict[\"type\"] = energy_type\n        result_dict[\"state\"] = state\n\n        return result_dict\n\n    def price_df_to_clean_dict(\n        self, eia_df: pl.DataFrame, energy_type: EnergyTypes, state: str\n    ) -&gt; dict[str, str | EnergyTypes | float]:\n        \"\"\"Clean DataFrame data consisting of EIA API data.\n\n        Args:\n            eia_df (pl.DataFrame): the DataFrame to clean\n            energy_type (EnergyTypes): the energy type\n            state (str): the state\n\n        Returns:\n            dict[str, str|EnergyTypes|float]: the dict\n        \"\"\"\n        result_dict = {}\n        for row in eia_df.rows(named=True):\n            year_month = f\"{row.get(\"year\")}-{row.get(\"month\")}\"\n            result_dict[year_month] = round(row.get(\"monthly_avg_price\"), 3)  # type: ignore\n        result_dict[\"type\"] = energy_type\n        result_dict[\"state\"] = state\n        return result_dict\n\n    # api to dict handler\n    def price_to_clean_dict(\n        self, price_struct: dict | pl.DataFrame, energy_type: EnergyTypes, state: str\n    ) -&gt; dict[str, str | EnergyTypes | float]:\n        \"\"\"Handle the different data types that EIA data could be stored in.\n\n        Args:\n            price_struct (dict | pl.DataFrame): a data structure containing the year, month, and price info\n            energy_type (EnergyTypes): the energy type\n            state (str): the state\n\n        Raises:\n            TypeError: raised if the type of `price_struct` is not supported\n\n        Returns:\n            dict[str, str|EnergyTypes|float]: the normalized and structured data in dict form\n        \"\"\"\n        match price_struct:\n            case dict():\n                return self.price_dict_to_clean_dict(price_struct, energy_type, state)\n            case pl.DataFrame():\n                return self.price_df_to_clean_dict(price_struct, energy_type, state)\n            case _:\n                raise TypeError(f\"Type not supported: {type(energy_type)}\")\n\n    # api interaction\n    def monthly_electricity_price_per_kwh(\n        self, state: str, start_date: datetime.date, end_date: datetime.date\n    ) -&gt; dict[str, Any]:\n        \"\"\"Get a state's average monthly energy price in cents per KWh.\n\n        Args:\n            state (str): the 2 character postal code of a state\n            start_date (datetime.date): the start date, inclusive\n            end_date (datetime.date): the end date, non inclusive\n\n        Returns:\n            dict: the dictionary in `year-month: price` form\n        \"\"\"\n        # cent/ kwh\n        url = f\"{self.eia_base_url}/electricity/retail-sales/data?data[]=price&amp;facets[sectorid][]=RES&amp;facets[stateid][]={state}&amp;frequency=monthly&amp;start={start_date.year}-{start_date.month:02}&amp;end={end_date.year}-{end_date.month:02}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n        eia_request = Helper.req_get_wrapper(url)\n        eia_request.raise_for_status()\n\n        return eia_request.json()\n\n    def monthly_ng_price_per_mcf(\n        self, state: str, start_date: datetime.date, end_date: datetime.date\n    ) -&gt; dict[str, Any]:\n        \"\"\"Get a state's average natural gas price in dollars per MCF.\n\n        Args:\n            state (str): the 2 character postal code of a state\n            start_date (datetime.date): the start date, inclusive\n            end_date (datetime.date): the end date, non inclusive\n\n        Returns:\n            dict: _description_\n        \"\"\"\n        # $/mcf\n        url = f\"https://api.eia.gov/v2/natural-gas/pri/sum/data/?frequency=monthly&amp;data[0]=value&amp;facets[duoarea][]=S{state}&amp;facets[process][]=PRS&amp;start={start_date.year}-{start_date.month:02}&amp;end={end_date.year}-{end_date.month:02}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n        eia_request = Helper.req_get_wrapper(url)\n        eia_request.raise_for_status()\n\n        return eia_request.json()\n\n    def monthly_heating_season_heating_oil_price_per_gal(\n        self, state: str, start_date: datetime.date, end_date: datetime.date\n    ) -&gt; pl.DataFrame:\n        \"\"\"Get a participating state's average heating oil price in dollars per gal.\n\n        Note:\n            Only certain states are tracked.\n\n        Args:\n            start_date (datetime.date): the start date, inclusive\n            end_date (datetime.date): the end date, non inclusive\n\n        Returns:\n            dict: _description_\n        \"\"\"\n        # heating season is Oct - march, $/gal\n        url = f\"https://api.eia.gov/v2/petroleum/pri/wfr/data/?frequency=weekly&amp;data[0]=value&amp;facets[duoarea][]=S{state}&amp;facets[product][]=EPD2F&amp;start={start_date}&amp;end={end_date}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n        eia_request = Helper.req_get_wrapper(url)\n        eia_request.raise_for_status()\n\n        json = eia_request.json()\n        # return self.price_json_to_dict(eia_request.json())\n        df = pl.DataFrame(json[\"response\"][\"data\"])\n        # df = df.with_columns(pl.col(\"period\").str.to_date().alias(\"period\"))\n        df = df.with_columns(pl.col(\"period\").str.strptime(pl.Date))\n        df = df.with_columns(\n            pl.col(\"period\").dt.year().alias(\"year\"),\n            pl.col(\"period\").dt.month().alias(\"month\"),\n        )\n\n        monthly_avg_price = (\n            df.group_by([\"year\", \"month\"])\n            .agg(pl.col(\"value\").mean().alias(\"monthly_avg_price\"))\n            .sort(\"year\", \"month\")\n        )\n\n        return monthly_avg_price\n\n    def _monthly_heating_season_propane_price_per_gal(\n        self, state: str, start_date: datetime.date, end_date: datetime.date\n    ) -&gt; pl.DataFrame:\n        \"\"\"Get a participating state's average propane price in dollars per gal.\n\n        Note:\n            Only certain states are tracked.\n\n        Args:\n            start_date (datetime.date): the start date, inclusive\n            end_date (datetime.date): the end date, non inclusive\n\n        Returns:\n            dict: _description_\n        \"\"\"\n        # heating season is Oct - march, $/gal\n        url = f\"https://api.eia.gov/v2/petroleum/pri/wfr/data/?frequency=weekly&amp;data[0]=value&amp;facets[duoarea][]=S{state}&amp;facets[product][]=EPLLPA&amp;start={start_date}&amp;end={end_date}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n        eia_request = Helper.req_get_wrapper(url)\n        eia_request.raise_for_status()\n\n        json = eia_request.json()\n        # return self.price_json_to_dict(eia_request.json())\n        df = pl.DataFrame(json[\"response\"][\"data\"])\n        # df = df.with_columns(pl.col(\"period\").str.to_date().alias(\"period\"))\n        df = df.with_columns(pl.col(\"period\").str.strptime(pl.Date))\n        df = df.with_columns(\n            pl.col(\"period\").dt.year().alias(\"year\"),\n            pl.col(\"period\").dt.month().alias(\"month\"),\n        )\n\n        monthly_avg_price = (\n            df.group_by([\"year\", \"month\"])\n            .agg(pl.col(\"value\").mean().alias(\"monthly_avg_price\"))\n            .sort(\"year\", \"month\")\n        )\n\n        return monthly_avg_price\n\n    def monthly_price_per_btu_by_energy_type(\n        self,\n        energy_type: EnergyTypes,\n        state: str,\n        start_date: datetime.date,\n        end_date: datetime.date,\n    ) -&gt; dict[str, str | EnergyTypes | float]:\n        \"\"\"Get the cost per BTU for the given energy type for the state, over the given period of time. Refer to EIA's documentation\n        for changes to data collection during certain years.\n\n        Args:\n            energy_type (EnergyTypes): The energy type\n            state (str): the 2 character postal abbreviation. Note that for heating oil, only certain states have this information collected\n            start_date (datetime.date): the date for which to start the search. Inclusive. Not that for heating oil, only heating months will be returned\n            end_date (datetime.date): the date for which to end the search. Non inclusive\n\n        Raises:\n            NotImplementedError: Invalid energy type\n\n        Returns:\n            dict: year-month: price in USD to BTU\n        \"\"\"\n        match energy_type:\n            case self.EnergyTypes.PROPANE:\n                return self._price_per_btu_converter(\n                    self.price_to_clean_dict(\n                        self._monthly_heating_season_propane_price_per_gal(\n                            state, start_date, end_date\n                        ),\n                        energy_type,\n                        state,\n                    )\n                )\n            case self.EnergyTypes.NATURAL_GAS:\n                return self._price_per_btu_converter(\n                    self.price_to_clean_dict(\n                        self.monthly_ng_price_per_mcf(state, start_date, end_date),\n                        energy_type,\n                        state,\n                    )\n                )\n            case self.EnergyTypes.ELECTRICITY:\n                return self._price_per_btu_converter(\n                    self.price_to_clean_dict(\n                        self.monthly_electricity_price_per_kwh(\n                            state, start_date, end_date\n                        ),\n                        energy_type,\n                        state,\n                    )\n                )\n            case self.EnergyTypes.HEATING_OIL:\n                return self._price_per_btu_converter(\n                    self.price_to_clean_dict(\n                        self.monthly_heating_season_heating_oil_price_per_gal(\n                            state, start_date, end_date\n                        ),\n                        energy_type,\n                        state,\n                    )\n                )\n            case _:\n                raise NotImplementedError(f\"Unsupported energy type: {energy_type}\")\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.monthly_electricity_price_per_kwh","title":"<code>monthly_electricity_price_per_kwh(state, start_date, end_date)</code>","text":"<p>Get a state's average monthly energy price in cents per KWh.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>the 2 character postal code of a state</p> required <code>start_date</code> <code>date</code> <p>the start date, inclusive</p> required <code>end_date</code> <code>date</code> <p>the end date, non inclusive</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>the dictionary in <code>year-month: price</code> form</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def monthly_electricity_price_per_kwh(\n    self, state: str, start_date: datetime.date, end_date: datetime.date\n) -&gt; dict[str, Any]:\n    \"\"\"Get a state's average monthly energy price in cents per KWh.\n\n    Args:\n        state (str): the 2 character postal code of a state\n        start_date (datetime.date): the start date, inclusive\n        end_date (datetime.date): the end date, non inclusive\n\n    Returns:\n        dict: the dictionary in `year-month: price` form\n    \"\"\"\n    # cent/ kwh\n    url = f\"{self.eia_base_url}/electricity/retail-sales/data?data[]=price&amp;facets[sectorid][]=RES&amp;facets[stateid][]={state}&amp;frequency=monthly&amp;start={start_date.year}-{start_date.month:02}&amp;end={end_date.year}-{end_date.month:02}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n    eia_request = Helper.req_get_wrapper(url)\n    eia_request.raise_for_status()\n\n    return eia_request.json()\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.monthly_heating_season_heating_oil_price_per_gal","title":"<code>monthly_heating_season_heating_oil_price_per_gal(state, start_date, end_date)</code>","text":"<p>Get a participating state's average heating oil price in dollars per gal.</p> Note <p>Only certain states are tracked.</p> <p>Parameters:</p> Name Type Description Default <code>start_date</code> <code>date</code> <p>the start date, inclusive</p> required <code>end_date</code> <code>date</code> <p>the end date, non inclusive</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>DataFrame</code> <p>description</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def monthly_heating_season_heating_oil_price_per_gal(\n    self, state: str, start_date: datetime.date, end_date: datetime.date\n) -&gt; pl.DataFrame:\n    \"\"\"Get a participating state's average heating oil price in dollars per gal.\n\n    Note:\n        Only certain states are tracked.\n\n    Args:\n        start_date (datetime.date): the start date, inclusive\n        end_date (datetime.date): the end date, non inclusive\n\n    Returns:\n        dict: _description_\n    \"\"\"\n    # heating season is Oct - march, $/gal\n    url = f\"https://api.eia.gov/v2/petroleum/pri/wfr/data/?frequency=weekly&amp;data[0]=value&amp;facets[duoarea][]=S{state}&amp;facets[product][]=EPD2F&amp;start={start_date}&amp;end={end_date}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n    eia_request = Helper.req_get_wrapper(url)\n    eia_request.raise_for_status()\n\n    json = eia_request.json()\n    # return self.price_json_to_dict(eia_request.json())\n    df = pl.DataFrame(json[\"response\"][\"data\"])\n    # df = df.with_columns(pl.col(\"period\").str.to_date().alias(\"period\"))\n    df = df.with_columns(pl.col(\"period\").str.strptime(pl.Date))\n    df = df.with_columns(\n        pl.col(\"period\").dt.year().alias(\"year\"),\n        pl.col(\"period\").dt.month().alias(\"month\"),\n    )\n\n    monthly_avg_price = (\n        df.group_by([\"year\", \"month\"])\n        .agg(pl.col(\"value\").mean().alias(\"monthly_avg_price\"))\n        .sort(\"year\", \"month\")\n    )\n\n    return monthly_avg_price\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.monthly_ng_price_per_mcf","title":"<code>monthly_ng_price_per_mcf(state, start_date, end_date)</code>","text":"<p>Get a state's average natural gas price in dollars per MCF.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>the 2 character postal code of a state</p> required <code>start_date</code> <code>date</code> <p>the start date, inclusive</p> required <code>end_date</code> <code>date</code> <p>the end date, non inclusive</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>description</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def monthly_ng_price_per_mcf(\n    self, state: str, start_date: datetime.date, end_date: datetime.date\n) -&gt; dict[str, Any]:\n    \"\"\"Get a state's average natural gas price in dollars per MCF.\n\n    Args:\n        state (str): the 2 character postal code of a state\n        start_date (datetime.date): the start date, inclusive\n        end_date (datetime.date): the end date, non inclusive\n\n    Returns:\n        dict: _description_\n    \"\"\"\n    # $/mcf\n    url = f\"https://api.eia.gov/v2/natural-gas/pri/sum/data/?frequency=monthly&amp;data[0]=value&amp;facets[duoarea][]=S{state}&amp;facets[process][]=PRS&amp;start={start_date.year}-{start_date.month:02}&amp;end={end_date.year}-{end_date.month:02}&amp;sort[0][column]=period&amp;sort[0][direction]=asc&amp;api_key={self.api_key}\"\n\n    eia_request = Helper.req_get_wrapper(url)\n    eia_request.raise_for_status()\n\n    return eia_request.json()\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.monthly_price_per_btu_by_energy_type","title":"<code>monthly_price_per_btu_by_energy_type(energy_type, state, start_date, end_date)</code>","text":"<p>Get the cost per BTU for the given energy type for the state, over the given period of time. Refer to EIA's documentation for changes to data collection during certain years.</p> <p>Parameters:</p> Name Type Description Default <code>energy_type</code> <code>EnergyTypes</code> <p>The energy type</p> required <code>state</code> <code>str</code> <p>the 2 character postal abbreviation. Note that for heating oil, only certain states have this information collected</p> required <code>start_date</code> <code>date</code> <p>the date for which to start the search. Inclusive. Not that for heating oil, only heating months will be returned</p> required <code>end_date</code> <code>date</code> <p>the date for which to end the search. Non inclusive</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Invalid energy type</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str | EnergyTypes | float]</code> <p>year-month: price in USD to BTU</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def monthly_price_per_btu_by_energy_type(\n    self,\n    energy_type: EnergyTypes,\n    state: str,\n    start_date: datetime.date,\n    end_date: datetime.date,\n) -&gt; dict[str, str | EnergyTypes | float]:\n    \"\"\"Get the cost per BTU for the given energy type for the state, over the given period of time. Refer to EIA's documentation\n    for changes to data collection during certain years.\n\n    Args:\n        energy_type (EnergyTypes): The energy type\n        state (str): the 2 character postal abbreviation. Note that for heating oil, only certain states have this information collected\n        start_date (datetime.date): the date for which to start the search. Inclusive. Not that for heating oil, only heating months will be returned\n        end_date (datetime.date): the date for which to end the search. Non inclusive\n\n    Raises:\n        NotImplementedError: Invalid energy type\n\n    Returns:\n        dict: year-month: price in USD to BTU\n    \"\"\"\n    match energy_type:\n        case self.EnergyTypes.PROPANE:\n            return self._price_per_btu_converter(\n                self.price_to_clean_dict(\n                    self._monthly_heating_season_propane_price_per_gal(\n                        state, start_date, end_date\n                    ),\n                    energy_type,\n                    state,\n                )\n            )\n        case self.EnergyTypes.NATURAL_GAS:\n            return self._price_per_btu_converter(\n                self.price_to_clean_dict(\n                    self.monthly_ng_price_per_mcf(state, start_date, end_date),\n                    energy_type,\n                    state,\n                )\n            )\n        case self.EnergyTypes.ELECTRICITY:\n            return self._price_per_btu_converter(\n                self.price_to_clean_dict(\n                    self.monthly_electricity_price_per_kwh(\n                        state, start_date, end_date\n                    ),\n                    energy_type,\n                    state,\n                )\n            )\n        case self.EnergyTypes.HEATING_OIL:\n            return self._price_per_btu_converter(\n                self.price_to_clean_dict(\n                    self.monthly_heating_season_heating_oil_price_per_gal(\n                        state, start_date, end_date\n                    ),\n                    energy_type,\n                    state,\n                )\n            )\n        case _:\n            raise NotImplementedError(f\"Unsupported energy type: {energy_type}\")\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.price_df_to_clean_dict","title":"<code>price_df_to_clean_dict(eia_df, energy_type, state)</code>","text":"<p>Clean DataFrame data consisting of EIA API data.</p> <p>Parameters:</p> Name Type Description Default <code>eia_df</code> <code>DataFrame</code> <p>the DataFrame to clean</p> required <code>energy_type</code> <code>EnergyTypes</code> <p>the energy type</p> required <code>state</code> <code>str</code> <p>the state</p> required <p>Returns:</p> Type Description <code>dict[str, str | EnergyTypes | float]</code> <p>dict[str, str|EnergyTypes|float]: the dict</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def price_df_to_clean_dict(\n    self, eia_df: pl.DataFrame, energy_type: EnergyTypes, state: str\n) -&gt; dict[str, str | EnergyTypes | float]:\n    \"\"\"Clean DataFrame data consisting of EIA API data.\n\n    Args:\n        eia_df (pl.DataFrame): the DataFrame to clean\n        energy_type (EnergyTypes): the energy type\n        state (str): the state\n\n    Returns:\n        dict[str, str|EnergyTypes|float]: the dict\n    \"\"\"\n    result_dict = {}\n    for row in eia_df.rows(named=True):\n        year_month = f\"{row.get(\"year\")}-{row.get(\"month\")}\"\n        result_dict[year_month] = round(row.get(\"monthly_avg_price\"), 3)  # type: ignore\n    result_dict[\"type\"] = energy_type\n    result_dict[\"state\"] = state\n    return result_dict\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.price_dict_to_clean_dict","title":"<code>price_dict_to_clean_dict(eia_json, energy_type, state)</code>","text":"<p>Clean JSON data returned by EIA's API.</p> <p>Parameters:</p> Name Type Description Default <code>eia_json</code> <code>_type_</code> <p>the dirty JSON</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str | EnergyTypes | float]</code> <p>cleaned JSON with state and energy type</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def price_dict_to_clean_dict(\n    self, eia_json: dict, energy_type: EnergyTypes, state: str\n) -&gt; dict[str, str | EnergyTypes | float]:\n    \"\"\"Clean JSON data returned by EIA's API.\n\n    Args:\n        eia_json (_type_): the dirty JSON\n\n    Returns:\n        dict: cleaned JSON with state and energy type\n    \"\"\"\n    # price key is different for electricity\n    accessor = \"value\"\n    if \"product\" not in eia_json[\"response\"][\"data\"][0]:\n        accessor = \"price\"\n\n    result_dict = {\n        entry[\"period\"]: entry[f\"{accessor}\"]\n        for entry in eia_json[\"response\"][\"data\"]\n    }\n    result_dict[\"type\"] = energy_type\n    result_dict[\"state\"] = state\n\n    return result_dict\n</code></pre>"},{"location":"UtilitiesPriceData/#src.UtilitiesPriceData.EIADataRetriever.price_to_clean_dict","title":"<code>price_to_clean_dict(price_struct, energy_type, state)</code>","text":"<p>Handle the different data types that EIA data could be stored in.</p> <p>Parameters:</p> Name Type Description Default <code>price_struct</code> <code>dict | DataFrame</code> <p>a data structure containing the year, month, and price info</p> required <code>energy_type</code> <code>EnergyTypes</code> <p>the energy type</p> required <code>state</code> <code>str</code> <p>the state</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>raised if the type of <code>price_struct</code> is not supported</p> <p>Returns:</p> Type Description <code>dict[str, str | EnergyTypes | float]</code> <p>dict[str, str|EnergyTypes|float]: the normalized and structured data in dict form</p> Source code in <code>src\\UtilitiesPriceData.py</code> <pre><code>def price_to_clean_dict(\n    self, price_struct: dict | pl.DataFrame, energy_type: EnergyTypes, state: str\n) -&gt; dict[str, str | EnergyTypes | float]:\n    \"\"\"Handle the different data types that EIA data could be stored in.\n\n    Args:\n        price_struct (dict | pl.DataFrame): a data structure containing the year, month, and price info\n        energy_type (EnergyTypes): the energy type\n        state (str): the state\n\n    Raises:\n        TypeError: raised if the type of `price_struct` is not supported\n\n    Returns:\n        dict[str, str|EnergyTypes|float]: the normalized and structured data in dict form\n    \"\"\"\n    match price_struct:\n        case dict():\n            return self.price_dict_to_clean_dict(price_struct, energy_type, state)\n        case pl.DataFrame():\n            return self.price_df_to_clean_dict(price_struct, energy_type, state)\n        case _:\n            raise TypeError(f\"Type not supported: {type(energy_type)}\")\n</code></pre>"},{"location":"csv_merge/","title":"Csv merge","text":""},{"location":"main/","title":"Main","text":""}]}